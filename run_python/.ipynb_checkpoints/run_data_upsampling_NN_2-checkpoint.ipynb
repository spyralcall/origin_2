{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# テキストファイルをnumpy配列に読み込み\n",
    "all_data = np.loadtxt(\"claim_toiawase_data_python.txt\")\n",
    "#numpy配列をDataFrame型に変換(でーたを見やすくするため)\n",
    "all_data_pd = pd.DataFrame(all_data)\n",
    "#DataFrame型の列名を設定\n",
    "all_data_pd.columns = [\"seq\", \"Imp\", \"Imp_val\", \"m_sum_neg\", \"c_neg\", \"m_sum_all\", \"m_sum_nzr\", \"Mag\", \"c_nzr\", \"c_all\", \"m_max\", \"s_min\", \"m_sdv_neg\", \n",
    "                   \"s_sdv_neg\", \"m_avg_neg\", \"s_avg_neg\", \"s_sdv_nzr\", \"m_sdv_all\", \"s_sdv_all\", \"s_avg_nzr\", \"m_avg_nzr\", \"s_avg_all\", \"Sc\",\n",
    "                   \"m_avg_all\", \"m_sum_pos\", \"c_pos\", \"m_min\", \"s_max\", \"m_sdv_pos\", \"s_sdv_pos\", \"m_avg_pos\", \"s_avg_pos\", \"m_sdv_nzr\"]\n",
    "print(all_data_pd)   #ImpとImp_valは同じ\n",
    "\n",
    "# 特徴量の部分のみall_Xに読み込み\n",
    "all_X = all_data[:9813,3:33]\n",
    "#ラベル部分をall_yに読み込み\n",
    "all_y = all_data[:9813, 2]\n",
    "print(all_X.shape)\n",
    "print(all_y)\n",
    "# print(type(all_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#アップサンプリング前のクラス1のデータ数とクラス0のデータ数の出力\n",
    "print(\"Number of class 1 samples before:\", all_y[all_y == 1].shape[0])\n",
    "print(\"Number of class 0 samples before:\", all_y[all_y == 0].shape[0])\n",
    "# print(all_X[all_y == 1])\n",
    "# print(all_X[all_y == 0])\n",
    "\n",
    "#クラスの1のサンプルの個数がクラス0と同じになるまで新しいサンプルを復元抽出\n",
    "X_upsampled, y_upsampled = resample(all_X[all_y == 1],\n",
    "                                    all_y[all_y == 1],\n",
    "                                    replace = True,\n",
    "                                    n_samples = all_X[all_y == 0].shape[0],\n",
    "                                    random_state = 123)\n",
    "# アップサンプリング後のクラス１のデータ数とデータの中身の出力\n",
    "print(\"Number of class 1 samples after:\", X_upsampled.shape[0])\n",
    "# print(X_upsampled)\n",
    "# 元のクラス０のサンプルにアップサンプリングしたクラス０のサブセットを結合\n",
    "X_bal = np.vstack((all_X[all_y == 0], X_upsampled))  #新しい特徴量集合\n",
    "y_bal = np.hstack((all_y[all_y == 0], y_upsampled))  #新しいラベル集合\n",
    "print(X_bal.shape, y_bal.shape)\n",
    "\n",
    "# print(X_bal)\n",
    "X_bal = X_bal[:16794,0:30]\n",
    "print(X_bal)\n",
    "# 新しい特徴量集合とラベル集合をそれぞれ7:3の割合で訓練データとテストデータに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, random_state=0, stratify=y_bal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "\n",
    "class Neural:\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, n_input, n_hidden, n_output, random_state):\n",
    "        numpy.random.seed(seed=random_state)\n",
    "        self.hidden_weight = numpy.random.random_sample((n_hidden, n_input + 1)) * 2 - 1 #n_hidden × n_input+1 の乱数配列生成（-1から1）\n",
    "        self.output_weight = numpy.random.random_sample((n_output, n_hidden + 1)) * 2 - 1 #n_output × n_hidden+1　の乱数配列生成（-1から1)\n",
    "        self.hidden_momentum = numpy.zeros((n_hidden, n_input + 1))  * 2 - 1\n",
    "        self.output_momentum = numpy.zeros((n_output, n_hidden + 1)) * 2 - 1\n",
    "\n",
    "# public method\n",
    "    def train(self, X, T, epsilon, mu, epoch):\n",
    "        self.error = numpy.zeros(epoch)\n",
    "        N = X.shape[0]\n",
    "        for epo in range(epoch):\n",
    "            for i in range(N):\n",
    "                x = X[i, :]\n",
    "                t = T[i]\n",
    "\n",
    "                self.__update_weight(x, t, epsilon, mu)\n",
    "\n",
    "            self.error[epo] = self.__calc_error(X, T)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        C = numpy.zeros(N).astype('int')\n",
    "        Y = numpy.zeros((N, X.shape[1]))\n",
    "        for i in range(N):\n",
    "            x = X[i, :]\n",
    "            z, y = self.__forward(x)\n",
    "\n",
    "            Y[i] = y      #予測ラベルの収納\n",
    "\n",
    "\n",
    "        return Y\n",
    "\n",
    "\n",
    "    def error_graph(self):\n",
    "        pyplot.ylim(0.0, 2.0)\n",
    "        pyplot.plot(numpy.arange(0, self.error.shape[0]), self.error)\n",
    "        pyplot.show()\n",
    "\n",
    "\n",
    "# private method\n",
    "    def __sigmoid(self, arr):\n",
    "        return numpy.vectorize(lambda x: 1.0 / (1.0 + math.exp(-x)))(arr)    #活性化関数はシグモイド関数\n",
    "\n",
    "\n",
    "    def __forward(self, x):\n",
    "        # z: output in hidden layer, y: output in output layer\n",
    "        z = self.__sigmoid(self.hidden_weight.dot(numpy.r_[numpy.array([1]), x]))\n",
    "        y = self.__sigmoid(self.output_weight.dot(numpy.r_[numpy.array([1]), z]))\n",
    "\n",
    "        return (z, y)\n",
    "\n",
    "    def __update_weight(self, x, t, epsilon, mu):\n",
    "        z, y = self.__forward(x)\n",
    "\n",
    "        # update output_weight\n",
    "        output_delta = (y - t) * y * (1.0 - y)\n",
    "        _output_weight = self.output_weight\n",
    "        self.output_weight -= epsilon * output_delta.reshape((-1, 1)) * numpy.r_[numpy.array([1]), z] - mu * self.output_momentum\n",
    "        self.output_momentum = self.output_weight - _output_weight\n",
    "\n",
    "        # update hidden_weight\n",
    "        hidden_delta = (self.output_weight[:, 1:].T.dot(output_delta)) * z * (1.0 - z)\n",
    "        _hidden_weight = self.hidden_weight\n",
    "        self.hidden_weight -= epsilon * hidden_delta.reshape((-1, 1)) * numpy.r_[numpy.array([1]), x]\n",
    "        self.hidden_momentum = self.hidden_weight - _hidden_weight\n",
    "\n",
    "\n",
    "    def __calc_error(self, X, T):\n",
    "        N = X.shape[0]\n",
    "        err = 0.0\n",
    "        for i in range(N):\n",
    "            x = X[i, :]\n",
    "            t = T[i]\n",
    "\n",
    "            z, y = self.__forward(x)\n",
    "            err += (y - t).dot((y - t).reshape((-1, 1))) / 2.0\n",
    "\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    X = X_train\n",
    "    T = y_train\n",
    "    N = X.shape[0] # number of data\n",
    "\n",
    "    input_size = X.shape[1]\n",
    "    hidden_size = 5\n",
    "    output_size = 1\n",
    "    epsilon = 0.1\n",
    "    mu = 0\n",
    "    epoch = 1\n",
    "    seed = 2\n",
    "\n",
    "    nn = Neural(input_size, hidden_size, output_size, seed)\n",
    "    nn.train(X, T, epsilon, mu, epoch)\n",
    "    nn.error_graph()\n",
    "\n",
    "    Y = nn.predict(X)\n",
    "    y_out = Y.mean(axis = 1)\n",
    "    y_pre = []\n",
    "    for i in y_out:\n",
    "        if 0.5 <= i:\n",
    "            y_pre.append(1.0)\n",
    "        elif 0.5>i:\n",
    "            y_pre.append(0.0)\n",
    "    y_pre = numpy.array(y_pre)\n",
    "\n",
    "    print(confusion_matrix(y_train, y_pre,labels=[1,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
